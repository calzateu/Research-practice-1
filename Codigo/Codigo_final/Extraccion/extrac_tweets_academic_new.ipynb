{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar llaves de la API\n",
    "La función `load_dotenv` lee el archivo `.env` e inivializa las variables de ambiente que allí están. Luego se puede acceder a dichas variables de ambiente con el módulo `os`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "consumer_key = os.environ[\"API_KEY\"]\n",
    "consumer_secret = os.environ[\"API_KEY_SECRET\"]\n",
    "access_token = os.environ[\"ACCESS_TOKEN\"]\n",
    "access_token_secret = os.environ[\"ACCESS_TOKEN_SECRET\"]\n",
    "bearer_token = os.environ[\"BEARER_TOKEN\"]\n",
    "\n",
    "\n",
    "client = tweepy.Client(\n",
    "  bearer_token=bearer_token,\n",
    "  consumer_key=consumer_key,\n",
    "  consumer_secret=consumer_secret,\n",
    "  access_token=access_token,\n",
    "  access_token_secret=access_token_secret,\n",
    "  wait_on_rate_limit=True,\n",
    "  return_type=requests.Response,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función recibe las listas de cuentas y tweets estraídos inicialmente para ir agregando las cuentas y los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_cuentas_usuarios_reponse(iteracion, lista_cuentas, lista_tweets, diccionario_tweets, response):\n",
    "    #diccionario_tweets.update(response)\n",
    "    #print(response['includes'])\n",
    "    for i in range(len(response['includes']['users'])):\n",
    "        diccionario_tweets['data'][iteracion + i] = response['data'][i]\n",
    "        diccionario_tweets['includes'][iteracion + i] = response['includes']['users'][i]\n",
    "        lista_cuentas.append(response['includes']['users'][i])\n",
    "        lista_tweets.append(response['data'][i]['text'])\n",
    "\n",
    "    print(len(lista_cuentas))\n",
    "    return len(diccionario_tweets['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_cuentas_usuarios_json(lista_cuentas, lista_tweets, diccionario_tweets):\n",
    "    with open(\"tweets.json\", 'r') as fp:\n",
    "        print(fp)\n",
    "        diccionario_tweets = json.load(fp)\n",
    "        for i in range(len(diccionario_tweets.keys())):\n",
    "            lista_cuentas.append(diccionario_tweets['includes']['users'][i])\n",
    "            lista_tweets.append(diccionario_tweets['data'][i]['text'])\n",
    "\n",
    "        print(len(lista_cuentas))\n",
    "        return len(diccionario_tweets['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte es donde se usa el query para buscar Tweets, y luego usa la función anterior para extraer los Tweets que se encuentran en los responses de la paginación que hace Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '-RT (deprimido lang:es -is:retweet deprimida OR desmotivado OR desmotivada OR llorar OR nervioso OR nerviosa OR preocupado OR preocupada OR triste OR vacío OR vacía OR agobiado OR agobiado OR agotado OR agotada OR angustiado OR angustiada OR ansiedad OR ansioso OR ansiosa OR cansado OR cansada OR decaído OR depresión OR depresivo OR depresiva OR desesperado OR desesperada OR insomnio)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Recent Tweets\n",
    "# This endpoint/method returns Tweets from the last seven days\n",
    "\n",
    "\n",
    "#query = 'depresión yo diagnosticado'\n",
    "#query = 'depresión yo tengo'\n",
    "#query = 'depresión yo tengo -lang:es #depresión #ansiedad'\n",
    "#query = 'Petro'\n",
    "#query = 'Saben? A veces me pongo en los zapatos de Gustavo Petro y hasta me compadezco de él'\n",
    "#query = 'eafit'\n",
    "\n",
    "# The method returns a Response object, a named tuple with data, includes,\n",
    "# errors, and meta fields\n",
    "\n",
    "cuentas_usuarios = []\n",
    "tweets = []\n",
    "#diccionario_tweets = {'data':{}, 'includes':{}, 'meta':{}}\n",
    "diccionario_tweets = {'data':{}, 'includes':{}}\n",
    "cont = 0\n",
    "for response in tweepy.Paginator(client.search_all_tweets,\n",
    "                                query,\n",
    "                                tweet_fields=['id', 'author_id', 'text'],\n",
    "                                user_fields=['id', 'username', 'location'],\n",
    "                                expansions='author_id',\n",
    "                                start_time='2021-01-20T00:00:00Z',\n",
    "                                end_time='2022-01-20T00:00:00Z',\n",
    "                                max_results=100, limit=100):#.flatten(limit=100):\n",
    "    cont = extraer_cuentas_usuarios_reponse(cont, cuentas_usuarios, tweets, diccionario_tweets, response)\n",
    "    #print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets.json\", \"w\") as fp:\n",
    "    json.dump(diccionario_tweets,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='tweets.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'users'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb Celda 11\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#diccionario_tweets = {'data':{}, 'includes':{}, 'meta':{}}\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m diccionario_tweets \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m:{}, \u001b[39m'\u001b[39m\u001b[39mincludes\u001b[39m\u001b[39m'\u001b[39m:{}}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m extraer_cuentas_usuarios_json(cuentas_usuarios, tweets, diccionario_tweets)\n",
      "\u001b[1;32m/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb Celda 11\u001b[0m in \u001b[0;36mextraer_cuentas_usuarios_json\u001b[0;34m(lista_cuentas, lista_tweets, diccionario_tweets)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m diccionario_tweets \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(fp)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(diccionario_tweets\u001b[39m.\u001b[39mkeys())):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     lista_cuentas\u001b[39m.\u001b[39mappend(diccionario_tweets[\u001b[39m'\u001b[39;49m\u001b[39mincludes\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39musers\u001b[39;49m\u001b[39m'\u001b[39;49m][i])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     lista_tweets\u001b[39m.\u001b[39mappend(diccionario_tweets[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cristian/Descargas/Universidad/6_2022-2/PI/Research-practice-1/Codigo/Codigo_final/extrac_tweets_academic_new.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(lista_cuentas))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'users'"
     ]
    }
   ],
   "source": [
    "cuentas_usuarios = []\n",
    "tweets = []\n",
    "#diccionario_tweets = {'data':{}, 'includes':{}, 'meta':{}}\n",
    "diccionario_tweets = {'data':{}, 'includes':{}}\n",
    "extraer_cuentas_usuarios_json(cuentas_usuarios, tweets, diccionario_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cuentas_usuarios))\n",
    "#print(cuentas_usuarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9781\n"
     ]
    }
   ],
   "source": [
    "print(len(diccionario_tweets['data'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'username': 'patlevesque00', 'name': 'patrick levesque', 'id': '1445142983179898889'}\n"
     ]
    }
   ],
   "source": [
    "print(cuentas_usuarios[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios = []\n",
    "ids_usuarios = []\n",
    "for usuario in cuentas_usuarios:\n",
    "    usuarios.append(usuario['username'])\n",
    "    ids_usuarios.append(usuario['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear el diccionario con el id que identifica a la persona y su correspondiente usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_ids_usuarios = dict(zip(ids_usuarios, usuarios))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraer tweets de usuarios\n",
    "Con se extraen los tweets de los usuarios que se conservaron (las personas de Colombia). Sin embargo, se crea esta función previa ya que al momento de extraer retweets, cuando estos son muy largos (más de 240 caracteres) queda cortado el mensaje, por lo que realicé esta función, que va verificando si es retweet y en caso afirmativo extrae su texto completo que se encuenta la parte de `includes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_tweets_usuarios(id, diccionario, response):\n",
    "    if id in list(diccionario.keys()):\n",
    "        lista_tweets = diccionario[id]\n",
    "    else:\n",
    "        lista_tweets = []\n",
    "\n",
    "    cont = 0\n",
    "    for i in range(len(response.data)):\n",
    "        if response.data[i]['referenced_tweets']:\n",
    "            try:\n",
    "                lista_tweets.append(response.includes['tweets'][cont].text)\n",
    "                cont += 1\n",
    "            except:\n",
    "                lista_tweets.append(response.data[i].text)\n",
    "\n",
    "        else:\n",
    "            lista_tweets.append(response.data[i].text)\n",
    "\n",
    "    diccionario[id] = lista_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_tweets = dict()\n",
    "for id_usuario in ids_usuarios:\n",
    "    for response in tweepy.Paginator(client.get_users_tweets,\n",
    "                                    id_usuario,\n",
    "                                    tweet_fields=['id', 'author_id', 'text', 'created_at'],\n",
    "                                    user_fields=['id', 'username', 'location', 'public_metrics'],\n",
    "                                    expansions='referenced_tweets.id',\n",
    "                                    #expansions='author_id',\n",
    "                                    max_results=100, limit=1):#.flatten(limit=100):\n",
    "        #extraer_tweets_usuarios(id_usuario, users_tweets, response)\n",
    "        #print(response.data[0].created_at)\n",
    "        users_tweets.update({diccionario_ids_usuarios[id_usuario]: response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"users_and_tweets.json\", \"w\") as fp:\n",
    "    json.dump(users_tweets,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar usuarios y Tweets en archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets.json\", \"w\") as fp:\n",
    "    json.dump(users_tweets,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"users.json\", \"w\") as fp:\n",
    "    json.dump(diccionario_ids_usuarios,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c9a5e9c047fc733d9313123a6e4ccecb6e7c397a0c0cfba3ec0c51c8c8008e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
