{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cargar llaves de la API**\n",
    "La función `load_dotenv` lee el archivo `.env` e inivializa las variables de ambiente que allí están. Luego se puede acceder a dichas variables de ambiente con el módulo `os`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "consumer_key = os.environ[\"API_KEY\"]\n",
    "consumer_secret = os.environ[\"API_KEY_SECRET\"]\n",
    "access_token = os.environ[\"ACCESS_TOKEN\"]\n",
    "access_token_secret = os.environ[\"ACCESS_TOKEN_SECRET\"]\n",
    "bearer_token = os.environ[\"BEARER_TOKEN\"]\n",
    "\n",
    "\n",
    "client = tweepy.Client(\n",
    "  bearer_token=bearer_token,\n",
    "  consumer_key=consumer_key,\n",
    "  consumer_secret=consumer_secret,\n",
    "  access_token=access_token,\n",
    "  access_token_secret=access_token_secret,\n",
    "  wait_on_rate_limit=True,\n",
    "  return_type=requests.Response,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función recibe las listas de cuentas y tweets estraídos inicialmente para ir agregando las cuentas y los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_cuentas_usuarios_reponse(iteracion, lista_cuentas, lista_tweets, diccionario_tweets, response):\n",
    "    for i in range(len(response['includes']['users'])):\n",
    "        diccionario_tweets['data'][iteracion + i] = response['data'][i]\n",
    "        diccionario_tweets['includes'][iteracion + i] = response['includes']['users'][i]\n",
    "        lista_cuentas.append(response['includes']['users'][i])\n",
    "        lista_tweets.append(response['data'][i]['text'])\n",
    "\n",
    "    print(len(lista_cuentas))\n",
    "    return len(diccionario_tweets['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_cuentas_usuarios_json(lista_cuentas, lista_tweets, diccionario_tweets):\n",
    "    with open(\"tweets.json\", 'r') as fp:\n",
    "        diccionario_tweets = json.load(fp)\n",
    "        for i in range(len(diccionario_tweets['data'].keys())):\n",
    "            lista_cuentas.append(diccionario_tweets['includes'][str(i)])\n",
    "            lista_tweets.append(diccionario_tweets['data'][str(i)]['text'])\n",
    "\n",
    "        print('Cantidad: ',len(lista_cuentas))\n",
    "        return len(diccionario_tweets['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte es donde se usa el query para buscar Tweets, y luego usa la función anterior para extraer los Tweets que se encuentran en los responses de la paginación que hace Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '-RT (deprimido lang:es -is:retweet deprimida OR desmotivado OR desmotivada OR llorar OR nervioso OR nerviosa OR preocupado OR preocupada OR triste OR vacío OR vacía OR agobiado OR agobiado OR agotado OR agotada OR angustiado OR angustiada OR ansiedad OR ansioso OR ansiosa OR cansado OR cansada OR decaído OR depresión OR depresivo OR depresiva OR desesperado OR desesperada OR insomnio)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Recent Tweets\n",
    "# This endpoint/method returns Tweets from the last seven days\n",
    "\n",
    "# The method returns a Response object, a named tuple with data, includes,\n",
    "# errors, and meta fields\n",
    "\n",
    "cuentas_usuarios = []\n",
    "tweets = []\n",
    "diccionario_tweets = {'data':{}, 'includes':{}}\n",
    "cont = 0\n",
    "for response in tweepy.Paginator(client.search_all_tweets,\n",
    "                                query,\n",
    "                                tweet_fields=['id', 'author_id', 'text'],\n",
    "                                user_fields=['id', 'username', 'location'],\n",
    "                                expansions='author_id',\n",
    "                                start_time='2021-01-20T00:00:00Z',\n",
    "                                end_time='2022-01-20T00:00:00Z',\n",
    "                                max_results=100, limit=100):\n",
    "    cont = extraer_cuentas_usuarios_reponse(cont, cuentas_usuarios, tweets, diccionario_tweets, response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el json sin limpiar (en raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets.json\", \"w\") as fp:\n",
    "    json.dump(diccionario_tweets,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extraer cuentas para después sacar los Tweets de cada usuario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets.json\") as fp:\n",
    "    diccionario_tweets = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad:  9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9788"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuentas_usuarios = []\n",
    "tweets = []\n",
    "diccionario_tweets = {'data':{}, 'includes':{}}\n",
    "extraer_cuentas_usuarios_json(cuentas_usuarios, tweets, diccionario_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9788\n"
     ]
    }
   ],
   "source": [
    "print(len(cuentas_usuarios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1445142983179898889', 'name': 'patrick levesque', 'username': 'patlevesque00'}\n"
     ]
    }
   ],
   "source": [
    "print(cuentas_usuarios[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios = []\n",
    "ids_usuarios = []\n",
    "for usuario in cuentas_usuarios:\n",
    "    usuarios.append(usuario['username'])\n",
    "    ids_usuarios.append(usuario['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear el diccionario con el id que identifica a la persona y su correspondiente usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_ids_usuarios = dict(zip(ids_usuarios, usuarios))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraer tweets de usuarios\n",
    "Con se extraen los tweets de los usuarios que se conservaron (las personas de Colombia). Sin embargo, se crea esta función previa ya que al momento de extraer retweets, cuando estos son muy largos (más de 240 caracteres) queda cortado el mensaje, por lo que realicé esta función, que va verificando si es retweet y en caso afirmativo extrae su texto completo que se encuenta la parte de `includes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_tweets_usuarios(id, diccionario, response):\n",
    "    if id in list(diccionario.keys()):\n",
    "        lista_tweets = diccionario[id]\n",
    "    else:\n",
    "        lista_tweets = []\n",
    "\n",
    "    cont = 0\n",
    "    for i in range(len(response.data)):\n",
    "        if response.data[i]['referenced_tweets']:\n",
    "            try:\n",
    "                lista_tweets.append(response.includes['tweets'][cont].text)\n",
    "                cont += 1\n",
    "            except:\n",
    "                lista_tweets.append(response.data[i].text)\n",
    "\n",
    "        else:\n",
    "            lista_tweets.append(response.data[i].text)\n",
    "\n",
    "    diccionario[id] = lista_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_tweets = dict()\n",
    "for id_usuario in ids_usuarios:\n",
    "    for response in tweepy.Paginator(client.get_users_tweets,\n",
    "                                    id_usuario,\n",
    "                                    tweet_fields=['id', 'author_id', 'text', 'created_at'],\n",
    "                                    user_fields=['id', 'username', 'location', 'public_metrics'],\n",
    "                                    expansions='referenced_tweets.id',\n",
    "                                    #expansions='author_id',\n",
    "                                    max_results=100, limit=1):#.flatten(limit=100):\n",
    "        #extraer_tweets_usuarios(id_usuario, users_tweets, response)\n",
    "        #print(response.data[0].created_at)\n",
    "        users_tweets.update({diccionario_ids_usuarios[id_usuario]: response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"users_and_tweets.json\", \"w\") as fp:\n",
    "    json.dump(users_tweets,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar usuarios y Tweets en archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets.json\", \"w\") as fp:\n",
    "    json.dump(users_tweets,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"users.json\", \"w\") as fp:\n",
    "    json.dump(diccionario_ids_usuarios,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c9a5e9c047fc733d9313123a6e4ccecb6e7c397a0c0cfba3ec0c51c8c8008e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
